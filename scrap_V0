import requests
import cloudscraper
from bs4 import BeautifulSoup

url = "https://www.epfl.ch/research/faculty-members/fr/"

scraper = cloudscraper.create_scraper()
page = scraper.get(url)
soup = BeautifulSoup(page.content, "html.parser")

noms_profs = soup.find_all('div',class_="contact-list-row")
noms = []


for prof in noms_profs:
    nom = prof.find("a").text
    #print(nom)
    noms.append(nom)

#----------------------------------------------------------------------------
profils = soup.find('div',class_="contact-list")
profile_site = []
tel = []


for link in soup.find_all('a', class_ = "contact-list-item"):
    href = link.get('href')
    if href != None:
        if "people" in href: # on prends le site profil 
            profile_site.append(href)
            #print("site pro = " +link.get('href'))
        if "+" in href: # On prend le num de télephone (atention au décalage par rapport au nom) ATENTION !!
            tel.append(href)
            #print("Num telephone = "+ link.get('href'))


TARGETS = len(noms) # la target max est len(noms)

buttons = []

for k in range (TARGETS):
    url_user = profile_site[k]
    response = requests.get(url_user)
    html = response.content

    soup_user = BeautifulSoup(html, 'html.parser')
    button = soup_user.find('button', {'id': 'collapse-arrow-0'})
    if button == None:
        buttons.append("Aucuns sujets publiés")
    else :
        button_text = button.get_text(strip=True)
        buttons.append(button_text)
    #print(buttons[k])
"""
for k in range(TARGETS):
    print("Nom = " + noms[k] , " | Sujets : "+ buttons[k])

"""
